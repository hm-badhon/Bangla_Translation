{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad758c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3090 Ti\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "import io\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sentencepiece as spm\n",
    "from torch.nn import TransformerEncoder, TransformerDecoder, TransformerEncoderLayer, TransformerDecoderLayer\n",
    "torch.manual_seed(0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89deeefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./process_data/merge_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94e737eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path):\n",
    "    with open(data_path, \"r\") as f:\n",
    "        data = f.readlines()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2adc773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8393f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 = list(map(lambda x: x.split(\"\\t\")[:2][::-1], data))\n",
    "data = list(map(lambda x: [x.split(\"\\t\")[0], x.split(\"\\t\")[1].replace(\"\\n\", \"\")], data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02ae7fc",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "754900b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = [\"০\",\"১\",\"২\",\"৩\",\"৪\",\"৫\",\"৬\",\"৭\",\"৮\",\"৯\"]\n",
    "en = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
    "\n",
    "bn_en = dict(map(lambda x, y: [x, y] ,bn, en ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4741cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'০': '0', '১': '1', '২': '2', '৩': '3', '৪': '4', '৫': '5', '৬': '6', '৭': '7', '৮': '8', '৯': '9'}\n"
     ]
    }
   ],
   "source": [
    "print(bn_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a8efc43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# coding=utf8\n",
    "# the above tag defines encoding for this document and is for Python 2.x compatibility\n",
    "\n",
    "import re\n",
    "\n",
    "# bn_to_en_number = lambda x\n",
    "bn_regex = r'[০-৯]+'\n",
    "en_regex = r'[0-9]+'\n",
    "\n",
    "def bn_number(bn_matches):\n",
    "    return [match[0] for matchNum, match in enumerate(bn_matches, start=1)]\n",
    "def en_number(en_matches):\n",
    "    return [match[0] for matchNum, match in enumerate(en_matches, start=1)]\n",
    "\n",
    "def convert_bn2en(bn_n):\n",
    "    bn2en = \"\".join(map(lambda x: bn_en[x], bn_n))\n",
    "    return bn2en\n",
    "\n",
    "def check_lenght(bn2en_n, en_n):\n",
    "    bn_lenght= list(map(len, bn2en_n))\n",
    "    en_lenght = list(map(len, en_n))\n",
    "    if len(bn_lenght) != len(en_lenght):\n",
    "        return {}, False\n",
    "    if bn_lenght != en_lenght:\n",
    "        bn2en_n = bn2en_n[::-1]\n",
    "    en_bn_map  = dict(map(lambda x, y: [x, y] , en_n, bn2en_n ))\n",
    "    return en_bn_map, True\n",
    "    \n",
    "    \n",
    "def get_number_data(bn, en):\n",
    "    bn_matches = list(re.finditer(bn_regex, bn, re.UNICODE))\n",
    "    en_matches = list(re.finditer(en_regex, en, re.UNICODE))\n",
    "    bn_n= bn_number(bn_matches)\n",
    "    en_n = en_number(en_matches)\n",
    "    bn2en_n= list(map(convert_bn2en, bn_n))\n",
    "    maping, status = check_lenght(bn2en_n, en_n)\n",
    "    return maping, status, en_n\n",
    "\n",
    "def get_process_data(i):    \n",
    "    maping, status, en_n= get_number_data((i[0]), (i[1]))\n",
    "    en_string = i[1]\n",
    "    if status:\n",
    "        for miss_anno_number in en_n:\n",
    "            en_string = en_string.replace(miss_anno_number, maping[miss_anno_number])\n",
    "    return [i[0], en_string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c206adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(map(get_process_data, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e819c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['বাকেরগঞ্জ জেলা নামটি ১৭৯৭ থেকে ১৯৯৩ সালপর্যন্ত ছিল',\n",
       "  'The name Bakerganj district was from 1797 to 1993 '],\n",
       " ['জেলা সদর বরিশালের নামে বিভাগের নামকরণ করা হয়',\n",
       "  'The division was named after the district headquarters Barisal '],\n",
       " ['বিবিধ  বাকেরগঞ্জ উপজেলার প্রায় ৮০ভাগের পেশাই চাষাবাদ',\n",
       "  'Miscellaneous occupations of about 80 per cent of Bakerganj upazila '],\n",
       " ['এই উপজেলার প্রায় ৮০ ভাগই ইসলাম ধর্ম অনুসারি',\n",
       "  'About 80 percent of this upazila is Islamic '],\n",
       " ['বাকি ২০ভাগ হিন্দু এবং খ্রীষ্টান',\n",
       "  'The remaining 20 percent are Hindus and Christians '],\n",
       " ['এই উপজেলায় ১টি সরকারি কলেজ রয়েছে',\n",
       "  'There is 1 government college in this upazila '],\n",
       " ['বাকেরগঞ্জ সরকারি কলেজ', 'Bakerganj Government College '],\n",
       " ['তালু  মুখগহ্বর  তালু মুখগহ্বরের ছাদ',\n",
       "  'The palate is the roof of the palate '],\n",
       " ['২০০৮ ২০০৮ গ্রেগরীয় বর্ষপঞ্জীর একটি অধিবর্ষ',\n",
       "  '2006 is a leap year in the Gregorian calendar '],\n",
       " ['১৯০০ ১৯০০ গ্রেগরীয় বর্ষপঞ্জীর একটি সাধারণ বছর',\n",
       "  '1900 is a typical year of the 1900 Gregorian calendar ']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6d45419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195775"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainen = [i[1] for i in data]\n",
    "val_en = [i[1] for i in data[-20000:]]\n",
    "len(trainen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77c9615b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Grand's style Grand's style is a deviant nature of mathematics \",\n",
       " 'The clause is 1 1 1 1 ',\n",
       " 'There is debate among mathematicians about this borrowing of infinite nature ',\n",
       " 'According to some, its value will be zero 0 ',\n",
       " 'According to others, the sum of this section is 1 ',\n",
       " 'This section is known as the Grand section ',\n",
       " 'He has made several acclaimed films ',\n",
       " 'He finished eighth in the 100 meters ',\n",
       " 'He finished the race in 12 60 seconds ',\n",
       " 'The film is directed by renowned director Belal Ahmed ']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_en[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "256ed044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The name Bakerganj district was from 1797 to 1993 ',\n",
       " 'The division was named after the district headquarters Barisal ',\n",
       " 'Miscellaneous occupations of about 80 per cent of Bakerganj upazila ',\n",
       " 'About 80 percent of this upazila is Islamic ',\n",
       " 'The remaining 20 percent are Hindus and Christians ',\n",
       " 'There is 1 government college in this upazila ',\n",
       " 'Bakerganj Government College ',\n",
       " 'The palate is the roof of the palate ',\n",
       " '2006 is a leap year in the Gregorian calendar ',\n",
       " '1900 is a typical year of the 1900 Gregorian calendar ']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainen[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "946583b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_tokenizer = spm.SentencePieceProcessor(model_file='model/bn_model.model')\n",
    "en_tokenizer = spm.SentencePieceProcessor(model_file='model/en_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1bbec599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_tokenizer.encode(\"All residents aged 20 to 59 years who live in Japan must enroll in public pension system.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96097394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bn_tokenizer.encode(\"আমি আবার বিয়ে করেছি।\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6171673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(bn_tokenizer.encode_as_pieces('টমকে জিজ্ঞাসা করুন।'))\n",
    "# print(bn_tokenizer.encode_as_ids('টমকে জিজ্ঞাসা করুন।'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1bc6a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchtext.vocab import vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f105defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import (TransformerEncoder, TransformerDecoder,\n",
    "                      TransformerEncoderLayer, TransformerDecoderLayer)\n",
    "\n",
    "\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, num_encoder_layers: int, num_decoder_layers: int,\n",
    "                 emb_size: int, src_vocab_size: int, tgt_vocab_size: int,\n",
    "                 dim_feedforward:int = 512, dropout:float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        encoder_layer = TransformerEncoderLayer(\n",
    "            d_model=emb_size, \n",
    "            nhead=NHEAD,\n",
    "            dim_feedforward=dim_feedforward\n",
    "            )\n",
    "        self.transformer_encoder = TransformerEncoder(\n",
    "            encoder_layer, \n",
    "            num_layers=num_encoder_layers\n",
    "            )\n",
    "        decoder_layer = TransformerDecoderLayer(\n",
    "            d_model=emb_size, \n",
    "            nhead=NHEAD,\n",
    "            dim_feedforward=dim_feedforward\n",
    "            )\n",
    "        self.transformer_decoder = TransformerDecoder(\n",
    "            decoder_layer, \n",
    "            num_layers=num_decoder_layers\n",
    "            )\n",
    "\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self, src: Tensor, trg: Tensor, src_mask: Tensor,\n",
    "                tgt_mask: Tensor, src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor, memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        memory = self.transformer_encoder(src_emb, src_mask, src_padding_mask)\n",
    "        outs = self.transformer_decoder(tgt_emb, memory, tgt_mask, None,\n",
    "                                        tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer_encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer_decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ba0825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size: int, dropout, maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding +\n",
    "                            self.pos_embedding[:token_embedding.size(0),:])\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7485ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=device).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e29ab45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('model/bn_vocab.pkl', 'rb')\n",
    "bn_vocal = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "831f0dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('model/en_vocab.pkl', 'rb')\n",
    "en_vocal = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aee59d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "NUM_ENCODER_LAYERS = 6\n",
    "NUM_DECODER_LAYERS = 6\n",
    "NUM_EPOCHS = 300\n",
    "\n",
    "SRC_VOCAB_SIZE = len(bn_vocal)\n",
    "TGT_VOCAB_SIZE = len(en_vocal)\n",
    "\n",
    "PAD_IDX = bn_vocal['<pad>']\n",
    "BOS_IDX = bn_vocal['<bos>']\n",
    "EOS_IDX = bn_vocal['<eos>']\n",
    "\n",
    "# transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS,\n",
    "#                                EMB_SIZE, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE,\n",
    "#                                  FFN_HID_DIM)\n",
    "# optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daada9c8",
   "metadata": {},
   "source": [
    "## Inference\n",
    "Here the inference script after load sentencepice train tokenizer model, vocal and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4054145",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac2a172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_tokenizer = spm.SentencePieceProcessor(model_file='model/bn_model.model')\n",
    "en_tokenizer = spm.SentencePieceProcessor(model_file='model/en_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "164aba80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (generator): Linear(in_features=512, out_features=30508, bias=True)\n",
       "  (src_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(50428, 512)\n",
       "  )\n",
       "  (tgt_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(30508, 512)\n",
       "  )\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"model/model_checkpoint.pt\"\n",
    "\n",
    "model = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS,\n",
    "                                 EMB_SIZE, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE,\n",
    "                                 FFN_HID_DIM)\n",
    "model.to(device)\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f7ffcbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(device)\n",
    "    src_mask = src_mask.to(device)\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(device)\n",
    "        memory_mask = torch.zeros(ys.shape[0], memory.shape[0]).to(device).type(torch.bool)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                                    .type(torch.bool)).to(device)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.item()\n",
    "        ys = torch.cat([ys,torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "def translate(model, src, src_vocab, tgt_vocab, src_tokenizer):\n",
    "#     model.eval()\n",
    "    tokens = [BOS_IDX] + [src_vocab.get_stoi()[tok] for tok in src_tokenizer.encode(src, out_type=str)]+ [EOS_IDX]\n",
    "    num_tokens = len(tokens)\n",
    "    src = (torch.LongTensor(tokens).reshape(num_tokens, 1) )\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    p_text = \" \".join([tgt_vocab.get_itos()[tok] for tok in tgt_tokens]).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
    "    pts = \" \".join(list(map(lambda x : x , p_text.replace(\" \", \"\").split(\"▁\"))))\n",
    "    return pts.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "544fa57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : বাকেরগঞ্জ জেলা নামটি ১৭৯৭ থেকে ১৯৯৩ সালপর্যন্ত ছিল\n",
      "Ground Truth : The name Bakerganj district was from 1797 to 1993 \n",
      "prediction: The name Bakerganj district was from 1797 to 1993\n",
      "================================\n",
      "input : জেলা সদর বরিশালের নামে বিভাগের নামকরণ করা হয়\n",
      "Ground Truth : The division was named after the district headquarters Barisal \n",
      "prediction: The division was named after the district headquarters Barisal\n",
      "================================\n",
      "input : বিবিধ  বাকেরগঞ্জ উপজেলার প্রায় ৮০ভাগের পেশাই চাষাবাদ\n",
      "Ground Truth : Miscellaneous occupations of about 80 per cent of Bakerganj upazila \n",
      "prediction: Miscellaneous occupations of about 80 per cent of Bakerganj upazila\n",
      "================================\n",
      "input : এই উপজেলার প্রায় ৮০ ভাগই ইসলাম ধর্ম অনুসারি\n",
      "Ground Truth : About 80 percent of this upazila is Islamic \n",
      "prediction: About 80 percent of this upazila is Islamic\n",
      "================================\n",
      "input : বাকি ২০ভাগ হিন্দু এবং খ্রীষ্টান\n",
      "Ground Truth : The remaining 20 percent are Hindus and Christians \n",
      "prediction: The remaining 20 percent are Hindus and Christians\n",
      "================================\n",
      "input : এই উপজেলায় ১টি সরকারি কলেজ রয়েছে\n",
      "Ground Truth : There is 1 government college in this upazila \n",
      "prediction: There is 1 government college in this upazila\n",
      "================================\n",
      "input : বাকেরগঞ্জ সরকারি কলেজ\n",
      "Ground Truth : Bakerganj Government College \n",
      "prediction: Bakerganj Government College\n",
      "================================\n",
      "input : তালু  মুখগহ্বর  তালু মুখগহ্বরের ছাদ\n",
      "Ground Truth : The palate is the roof of the palate \n",
      "prediction: The palate is the roof of the palate\n",
      "================================\n",
      "input : ২০০৮ ২০০৮ গ্রেগরীয় বর্ষপঞ্জীর একটি অধিবর্ষ\n",
      "Ground Truth : 2006 is a leap year in the Gregorian calendar \n",
      "prediction: 2006 is a leap year in the Gregorian calendar\n",
      "================================\n",
      "input : ১৯০০ ১৯০০ গ্রেগরীয় বর্ষপঞ্জীর একটি সাধারণ বছর\n",
      "Ground Truth : 1900 is a typical year of the 1900 Gregorian calendar \n",
      "prediction: 1900 is a typical year of the 1900 Gregorian calendar\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "for i in data[-10:]:\n",
    "    text = \"আমি আবার বিয়ে করেছি।\"\n",
    "    pre = translate(model, i[0], bn_vocal, en_vocal, bn_tokenizer)\n",
    "    print(f\"input : {i[0]}\")\n",
    "    print(f\"Ground Truth : {i[1]}\")\n",
    "    print(f\"prediction: {pre}\")\n",
    "    print(\"================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ed68c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# very short\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "def get_token(text):\n",
    "    return en_tokenizer.encode_as_pieces(text)\n",
    "def get_blue_score(gt, pt):\n",
    "    score = sentence_bleu(gt, pt)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b38aa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluation(text):\n",
    "    pre = translate(model, text[0], bn_vocab, en_vocab, bn_tokenizer)\n",
    "    gt = tokenize_text = get_token(text[1])\n",
    "    pt = tokenize_text = get_token(pre)\n",
    "#     print(gt, pt)\n",
    "    score = get_blue_score([gt], pt)\n",
    "#     print(score)\n",
    "    return score\n",
    "    \n",
    "score = list(map(evaluation, data))\n",
    "print(\"BLUE SCORE : \", sum(score)/len(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cda61ae",
   "metadata": {},
   "source": [
    "## Reference\n",
    "1. https://torchtutorialstaging.z5.web.core.windows.net/beginner/translation_transformer.html\n",
    "2. https://arusl.medium.com/japanese-english-language-translation-with-transformer-using-pytorch-243738146806\n",
    "3. https://github.com/hyunwoongko/transformer\n",
    "4. https://www.kaggle.com/datasets/ari994/banglaenglishtransliteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2d555b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
