{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ad758c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3090 Ti\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "import io\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sentencepiece as spm\n",
    "from torch.nn import TransformerEncoder, TransformerDecoder, TransformerEncoderLayer, TransformerDecoderLayer\n",
    "torch.manual_seed(0)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "89deeefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./process_data/merge_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "94e737eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path):\n",
    "    with open(data_path, \"r\") as f:\n",
    "        data = f.readlines()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2adc773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "da321528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['যাও।\\tGo.\\n',\n",
       " 'যান।\\tGo.\\n',\n",
       " 'যা।\\tGo.\\n',\n",
       " 'পালাও!\\tRun!\\n',\n",
       " 'পালান!\\tRun!\\n',\n",
       " 'কে?\\tWho?\\n',\n",
       " 'আগুন!\\tFire!\\n',\n",
       " 'বাঁচাও!\\tHelp!\\n',\n",
       " 'বাঁচান!\\tHelp!\\n',\n",
       " 'থামুন!\\tStop!\\n']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8393f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 = list(map(lambda x: x.split(\"\\t\")[:2][::-1], data))\n",
    "data = list(map(lambda x: [x.split(\"\\t\")[0], x.split(\"\\t\")[1].replace(\"\\n\", \"\")], data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5f35c7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['যাও।', 'Go.'],\n",
       " ['যান।', 'Go.'],\n",
       " ['যা।', 'Go.'],\n",
       " ['পালাও!', 'Run!'],\n",
       " ['পালান!', 'Run!'],\n",
       " ['কে?', 'Who?'],\n",
       " ['আগুন!', 'Fire!'],\n",
       " ['বাঁচাও!', 'Help!'],\n",
       " ['বাঁচান!', 'Help!'],\n",
       " ['থামুন!', 'Stop!']]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02ae7fc",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "754900b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = [\"০\",\"১\",\"২\",\"৩\",\"৪\",\"৫\",\"৬\",\"৭\",\"৮\",\"৯\"]\n",
    "en = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
    "\n",
    "bn_en = dict(map(lambda x, y: [x, y] ,bn, en ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a4741cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'০': '0', '১': '1', '২': '2', '৩': '3', '৪': '4', '৫': '5', '৬': '6', '৭': '7', '৮': '8', '৯': '9'}\n"
     ]
    }
   ],
   "source": [
    "print(bn_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5a8efc43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# coding=utf8\n",
    "# the above tag defines encoding for this document and is for Python 2.x compatibility\n",
    "\n",
    "import re\n",
    "\n",
    "# bn_to_en_number = lambda x\n",
    "bn_regex = r'[০-৯]+'\n",
    "en_regex = r'[0-9]+'\n",
    "\n",
    "def bn_number(bn_matches):\n",
    "    return [match[0] for matchNum, match in enumerate(bn_matches, start=1)]\n",
    "def en_number(en_matches):\n",
    "    return [match[0] for matchNum, match in enumerate(en_matches, start=1)]\n",
    "\n",
    "def convert_bn2en(bn_n):\n",
    "    bn2en = \"\".join(map(lambda x: bn_en[x], bn_n))\n",
    "    return bn2en\n",
    "\n",
    "def check_lenght(bn2en_n, en_n):\n",
    "    bn_lenght= list(map(len, bn2en_n))\n",
    "    en_lenght = list(map(len, en_n))\n",
    "    if len(bn_lenght) != len(en_lenght):\n",
    "        return {}, False\n",
    "    if bn_lenght != en_lenght:\n",
    "        bn2en_n = bn2en_n[::-1]\n",
    "    en_bn_map  = dict(map(lambda x, y: [x, y] , en_n, bn2en_n ))\n",
    "    return en_bn_map, True\n",
    "    \n",
    "    \n",
    "def get_number_data(bn, en):\n",
    "    bn_matches = list(re.finditer(bn_regex, bn, re.UNICODE))\n",
    "    en_matches = list(re.finditer(en_regex, en, re.UNICODE))\n",
    "    bn_n= bn_number(bn_matches)\n",
    "    en_n = en_number(en_matches)\n",
    "    bn2en_n= list(map(convert_bn2en, bn_n))\n",
    "    maping, status = check_lenght(bn2en_n, en_n)\n",
    "    return maping, status, en_n\n",
    "\n",
    "def get_process_data(i):    \n",
    "    maping, status, en_n= get_number_data((i[0]), (i[1]))\n",
    "    en_string = i[1]\n",
    "    if status:\n",
    "        for miss_anno_number in en_n:\n",
    "            en_string = en_string.replace(miss_anno_number, maping[miss_anno_number])\n",
    "    return [i[0], en_string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7c206adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(map(get_process_data, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2e819c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['বাকেরগঞ্জ জেলা নামটি ১৭৯৭ থেকে ১৯৯৩ সালপর্যন্ত ছিল',\n",
       "  'The name Bakerganj district was from 1797 to 1993 '],\n",
       " ['জেলা সদর বরিশালের নামে বিভাগের নামকরণ করা হয়',\n",
       "  'The division was named after the district headquarters Barisal '],\n",
       " ['বিবিধ  বাকেরগঞ্জ উপজেলার প্রায় ৮০ভাগের পেশাই চাষাবাদ',\n",
       "  'Miscellaneous occupations of about 80 per cent of Bakerganj upazila '],\n",
       " ['এই উপজেলার প্রায় ৮০ ভাগই ইসলাম ধর্ম অনুসারি',\n",
       "  'About 80 percent of this upazila is Islamic '],\n",
       " ['বাকি ২০ভাগ হিন্দু এবং খ্রীষ্টান',\n",
       "  'The remaining 20 percent are Hindus and Christians '],\n",
       " ['এই উপজেলায় ১টি সরকারি কলেজ রয়েছে',\n",
       "  'There is 1 government college in this upazila '],\n",
       " ['বাকেরগঞ্জ সরকারি কলেজ', 'Bakerganj Government College '],\n",
       " ['তালু  মুখগহ্বর  তালু মুখগহ্বরের ছাদ',\n",
       "  'The palate is the roof of the palate '],\n",
       " ['২০০৮ ২০০৮ গ্রেগরীয় বর্ষপঞ্জীর একটি অধিবর্ষ',\n",
       "  '2006 is a leap year in the Gregorian calendar '],\n",
       " ['১৯০০ ১৯০০ গ্রেগরীয় বর্ষপঞ্জীর একটি সাধারণ বছর',\n",
       "  '1900 is a typical year of the 1900 Gregorian calendar ']]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "69549a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195775"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainbn = [i[0] for i in data]\n",
    "val_bn = [i[0] for i in data[-20000:]]\n",
    "len(trainbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5998c259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['গ্রান্দের ধারা গ্রান্দের ধারা হলো গণিতের একটি বিচ্যুত প্রকৃতির ধারা',\n",
       " 'ধারাটি হচ্ছে ১   ১   ১   ১      ',\n",
       " 'অসীম প্রকৃতির এই ধারটি নিয়ে গণিতবিদদের মধ্যে বিতর্ক রয়েছে',\n",
       " 'কারও মতে  এর মান হবে শূন্য  ০ ',\n",
       " 'অন্যদের মতে এই ধারার যোগফল এক  ১ ',\n",
       " 'এই ধারাই গ্র্যান্দের ধারা হিসেবে পরিচিত',\n",
       " 'তিনি বেশ কয়েকটি দর্শকনন্দিত চলচ্চিত্র নির্মাণ করেছেন',\n",
       " 'তিনি ১০০মিটার হিটে অষ্টম হয়ে প্রতিযোগিতা শেষ করেন',\n",
       " 'তিনি ১২ ৬০সেকেন্ড সময়ে দৌড় শেষ করেন',\n",
       " 'চলচ্চিত্রটি পরিচালনা করেছেন বিখ্যাত পরিচালক বেলাল আহমেদ']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_bn[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b6d45419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195775"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainen = [i[1] for i in data]\n",
    "val_en = [i[1] for i in data[-20000:]]\n",
    "len(trainen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "77c9615b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Grand's style Grand's style is a deviant nature of mathematics \",\n",
       " 'The clause is 1 1 1 1 ',\n",
       " 'There is debate among mathematicians about this borrowing of infinite nature ',\n",
       " 'According to some, its value will be zero 0 ',\n",
       " 'According to others, the sum of this section is 1 ',\n",
       " 'This section is known as the Grand section ',\n",
       " 'He has made several acclaimed films ',\n",
       " 'He finished eighth in the 100 meters ',\n",
       " 'He finished the race in 12 60 seconds ',\n",
       " 'The film is directed by renowned director Belal Ahmed ']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_en[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9e77c473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['বাকেরগঞ্জ জেলা নামটি ১৭৯৭ থেকে ১৯৯৩ সালপর্যন্ত ছিল',\n",
       " 'জেলা সদর বরিশালের নামে বিভাগের নামকরণ করা হয়',\n",
       " 'বিবিধ  বাকেরগঞ্জ উপজেলার প্রায় ৮০ভাগের পেশাই চাষাবাদ',\n",
       " 'এই উপজেলার প্রায় ৮০ ভাগই ইসলাম ধর্ম অনুসারি',\n",
       " 'বাকি ২০ভাগ হিন্দু এবং খ্রীষ্টান',\n",
       " 'এই উপজেলায় ১টি সরকারি কলেজ রয়েছে',\n",
       " 'বাকেরগঞ্জ সরকারি কলেজ',\n",
       " 'তালু  মুখগহ্বর  তালু মুখগহ্বরের ছাদ',\n",
       " '২০০৮ ২০০৮ গ্রেগরীয় বর্ষপঞ্জীর একটি অধিবর্ষ',\n",
       " '১৯০০ ১৯০০ গ্রেগরীয় বর্ষপঞ্জীর একটি সাধারণ বছর']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainbn[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "256ed044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The name Bakerganj district was from 1797 to 1993 ',\n",
       " 'The division was named after the district headquarters Barisal ',\n",
       " 'Miscellaneous occupations of about 80 per cent of Bakerganj upazila ',\n",
       " 'About 80 percent of this upazila is Islamic ',\n",
       " 'The remaining 20 percent are Hindus and Christians ',\n",
       " 'There is 1 government college in this upazila ',\n",
       " 'Bakerganj Government College ',\n",
       " 'The palate is the roof of the palate ',\n",
       " '2006 is a leap year in the Gregorian calendar ',\n",
       " '1900 is a typical year of the 1900 Gregorian calendar ']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainen[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "054cd2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "process_data_path = \"process_data\"\n",
    "# os.makedirs(process_data_path, exits_ok= True)\n",
    "os.makedirs(process_data_path, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "27fc0203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_txt_file(file_path, data, encoding=\"utf-8\"):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for key in data:\n",
    "            if isinstance(key, list):\n",
    "                key = key[0]\n",
    "            f.write(key+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a46ea05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt_file(os.path.join(process_data_path, \"bn_data.txt\"), trainbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5f3beba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt_file(os.path.join(process_data_path,\"en_data.txt\"), trainen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ea840781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data_write_txt_file(file_path, bn_data, en_data, encoding=\"utf-8\"):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for bn, en in zip(bn_data, en_data):\n",
    "#             if isinstance(key, list):\n",
    "#                 key = key[0]\n",
    "            f.write(bn+\"\\t\"+en+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "088ece19",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data_write_txt_file(os.path.join(process_data_path, \"merge_data.txt\"), trainbn, trainen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "60265503",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"model\"\n",
    "os.makedirs(model_path, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "65467bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "def train_tokenizer(text_path=\"text.txt\", model_prefix=\"model/bn_model\", vocab_size=30000):\n",
    "    spm.SentencePieceTrainer.train(f'--input={text_path} --model_prefix={model_prefix} --user_defined_symbols=<sep>,<cls> --vocab_size={vocab_size}')\n",
    "    bn_sp = spm.SentencePieceProcessor()\n",
    "    bn_sp.load(os.path.join(model_path, 'bn_model.model'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "88cfed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_data_path = \"process_data/bn_data.txt\"\n",
    "en_data_path = \"process_data/en_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fa3c66b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=process_data/bn_data.txt --model_prefix=model/bn_model --user_defined_symbols=<sep>,<cls> --vocab_size=50000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: process_data/bn_data.txt\n",
      "  input_format: \n",
      "  model_prefix: model/bn_model\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 50000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: <sep>\n",
      "  user_defined_symbols: <cls>\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(350) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(181) LOG(INFO) Loading corpus: process_data/bn_data.txt\n",
      "trainer_interface.cc(406) LOG(INFO) Loaded all 195775 sentences\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <sep>\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <cls>\n",
      "trainer_interface.cc(427) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(536) LOG(INFO) all chars count=9774999\n",
      "trainer_interface.cc(547) LOG(INFO) Done: 99.9514% characters are covered.\n",
      "trainer_interface.cc(557) LOG(INFO) Alphabet size=111\n",
      "trainer_interface.cc(558) LOG(INFO) Final character coverage=0.999514\n",
      "trainer_interface.cc(590) LOG(INFO) Done! preprocessed 195775 sentences.\n",
      "unigram_model_trainer.cc(146) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(150) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(201) LOG(INFO) Initialized 237532 seed sentencepieces\n",
      "trainer_interface.cc(596) LOG(INFO) Tokenizing input sentences with whitespace: 195775\n",
      "trainer_interface.cc(607) LOG(INFO) Done! 126842\n",
      "unigram_model_trainer.cc(491) LOG(INFO) Using 126842 sentences for EM training\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=77158 obj=11.6681 num_tokens=228829 num_tokens/piece=2.96572\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=65201 obj=9.82219 num_tokens=229850 num_tokens/piece=3.52525\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=54959 obj=9.77723 num_tokens=236898 num_tokens/piece=4.31045\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=54803 obj=9.76111 num_tokens=237024 num_tokens/piece=4.32502\n",
      "trainer_interface.cc(685) LOG(INFO) Saving model: model/bn_model.model\n",
      "trainer_interface.cc(697) LOG(INFO) Saving vocabs: model/bn_model.vocab\n"
     ]
    }
   ],
   "source": [
    "train_tokenizer(\n",
    "    text_path = bn_data_path,\n",
    "    model_prefix = \"model/bn_model\",\n",
    "    vocab_size = 50000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "47994f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=process_data/en_data.txt --model_prefix=model/en_model --user_defined_symbols=<sep>,<cls> --vocab_size=30000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: process_data/en_data.txt\n",
      "  input_format: \n",
      "  model_prefix: model/en_model\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 30000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: <sep>\n",
      "  user_defined_symbols: <cls>\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(350) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(181) LOG(INFO) Loading corpus: process_data/en_data.txt\n",
      "trainer_interface.cc(406) LOG(INFO) Loaded all 195775 sentences\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <sep>\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <cls>\n",
      "trainer_interface.cc(427) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(536) LOG(INFO) all chars count=10587350\n",
      "trainer_interface.cc(547) LOG(INFO) Done: 99.9515% characters are covered.\n",
      "trainer_interface.cc(557) LOG(INFO) Alphabet size=67\n",
      "trainer_interface.cc(558) LOG(INFO) Final character coverage=0.999515\n",
      "trainer_interface.cc(590) LOG(INFO) Done! preprocessed 195775 sentences.\n",
      "unigram_model_trainer.cc(146) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(150) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(201) LOG(INFO) Initialized 162603 seed sentencepieces\n",
      "trainer_interface.cc(596) LOG(INFO) Tokenizing input sentences with whitespace: 195775\n",
      "trainer_interface.cc(607) LOG(INFO) Done! 83662\n",
      "unigram_model_trainer.cc(491) LOG(INFO) Using 83662 sentences for EM training\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=60194 obj=10.2612 num_tokens=152390 num_tokens/piece=2.53165\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=50022 obj=8.31344 num_tokens=152823 num_tokens/piece=3.05512\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=37511 obj=8.28088 num_tokens=163654 num_tokens/piece=4.36283\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=37490 obj=8.26186 num_tokens=163662 num_tokens/piece=4.36548\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=33000 obj=8.28845 num_tokens=170020 num_tokens/piece=5.15212\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=33000 obj=8.28117 num_tokens=170010 num_tokens/piece=5.15182\n",
      "trainer_interface.cc(685) LOG(INFO) Saving model: model/en_model.model\n",
      "trainer_interface.cc(697) LOG(INFO) Saving vocabs: model/en_model.vocab\n"
     ]
    }
   ],
   "source": [
    "train_tokenizer(\n",
    "    text_path = en_data_path,\n",
    "    model_prefix = \"model/en_model\",\n",
    "    vocab_size = 30000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "946583b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_tokenizer = spm.SentencePieceProcessor(model_file='model/bn_model.model')\n",
    "en_tokenizer = spm.SentencePieceProcessor(model_file='model/en_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1bbec599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[302,\n",
       " 2625,\n",
       " 164,\n",
       " 48,\n",
       " 349,\n",
       " 15,\n",
       " 2120,\n",
       " 92,\n",
       " 347,\n",
       " 342,\n",
       " 7,\n",
       " 670,\n",
       " 2010,\n",
       " 4786,\n",
       " 7,\n",
       " 953,\n",
       " 19800,\n",
       " 292,\n",
       " 39]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tokenizer.encode(\"All residents aged 20 to 59 years who live in Japan must enroll in public pension system.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "96097394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[148, 200, 315, 4654, 50]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_tokenizer.encode(\"আমি আবার বিয়ে করেছি।\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c6171673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁টমকে', '▁জিজ্ঞাসা', '▁করুন', '।']\n",
      "[2429, 4620, 2745, 50]\n"
     ]
    }
   ],
   "source": [
    "print(bn_tokenizer.encode_as_pieces('টমকে জিজ্ঞাসা করুন।'))\n",
    "print(bn_tokenizer.encode_as_ids('টমকে জিজ্ঞাসা করুন।'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a1bc6a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import vocab\n",
    "def build_vocab(sentences, tokenizer):\n",
    "    counter = Counter()\n",
    "    for sentence in sentences:\n",
    "        if isinstance(sentence, list):\n",
    "            sentence = sentence[0]\n",
    "        counter.update(tokenizer.encode(sentence, out_type=str))\n",
    "    return vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'], special_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3bb23f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.0'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ca6fc898",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_vocab = build_vocab(trainbn, bn_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "346f4426",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab = build_vocab(trainen, en_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0cbacd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(bn, en):\n",
    "    data = []\n",
    "    for (raw_bn, raw_en) in zip(bn, en):\n",
    "        bn_tensor_ = torch.tensor([bn_vocab[token] for token in bn_tokenizer.encode(raw_bn, out_type=str)],dtype=torch.long)\n",
    "        en_tensor_ = torch.tensor([en_vocab[token] for token in en_tokenizer.encode(raw_en, out_type=str)],dtype=torch.long)\n",
    "        data.append((bn_tensor_, en_tensor_))\n",
    "    return data\n",
    "train_data = data_process(trainbn, trainen)\n",
    "val_data = data_process(val_bn, val_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "20bea7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 150\n",
    "PAD_IDX = bn_vocab['<pad>']\n",
    "BOS_IDX = bn_vocab['<bos>']\n",
    "EOS_IDX = bn_vocab['<eos>']\n",
    "\n",
    "def generate_batch(data_batch):\n",
    "    bn_batch, en_batch = [], []\n",
    "    for (bn_item, en_item) in data_batch:\n",
    "        bn_batch.append(torch.cat([torch.tensor([BOS_IDX]), bn_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "        en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
    "    bn_batch = pad_sequence(bn_batch, padding_value=PAD_IDX)\n",
    "    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
    "    return bn_batch, en_batch\n",
    "\n",
    "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,shuffle=True, collate_fn=generate_batch)\n",
    "val_iter = DataLoader(val_data, batch_size=BATCH_SIZE,shuffle=True, collate_fn=generate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f105defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import (TransformerEncoder, TransformerDecoder,\n",
    "                      TransformerEncoderLayer, TransformerDecoderLayer)\n",
    "\n",
    "\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, num_encoder_layers: int, num_decoder_layers: int,\n",
    "                 emb_size: int, src_vocab_size: int, tgt_vocab_size: int,\n",
    "                 dim_feedforward:int = 512, dropout:float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        encoder_layer = TransformerEncoderLayer(\n",
    "            d_model=emb_size, \n",
    "            nhead=NHEAD,\n",
    "            dim_feedforward=dim_feedforward\n",
    "            )\n",
    "        self.transformer_encoder = TransformerEncoder(\n",
    "            encoder_layer, \n",
    "            num_layers=num_encoder_layers\n",
    "            )\n",
    "        decoder_layer = TransformerDecoderLayer(\n",
    "            d_model=emb_size, \n",
    "            nhead=NHEAD,\n",
    "            dim_feedforward=dim_feedforward\n",
    "            )\n",
    "        self.transformer_decoder = TransformerDecoder(\n",
    "            decoder_layer, \n",
    "            num_layers=num_decoder_layers\n",
    "            )\n",
    "\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self, src: Tensor, trg: Tensor, src_mask: Tensor,\n",
    "                tgt_mask: Tensor, src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor, memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        memory = self.transformer_encoder(src_emb, src_mask, src_padding_mask)\n",
    "        outs = self.transformer_decoder(tgt_emb, memory, tgt_mask, None,\n",
    "                                        tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer_encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer_decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5ba0825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size: int, dropout, maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding +\n",
    "                            self.pos_embedding[:token_embedding.size(0),:])\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b7485ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=device).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "aee59d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "SRC_VOCAB_SIZE = len(bn_vocab)\n",
    "TGT_VOCAB_SIZE = len(en_vocab)\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "BATCH_SIZE = 150\n",
    "NUM_ENCODER_LAYERS = 6\n",
    "NUM_DECODER_LAYERS = 6\n",
    "NUM_EPOCHS = 300\n",
    "\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS,\n",
    "                                 EMB_SIZE, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE,\n",
    "                                 FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(device)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "def train_epoch(model, train_iter, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    for idx, (src, tgt) in enumerate(train_iter):\n",
    "#         print(\"training iter : \", idx)\n",
    "#     for idx in tqdm(range(len(train_iter))):\n",
    "#         src, tgt = train_iter[idx]\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,\n",
    "                                src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:,:]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "    return losses / len(train_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c2dabc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    for idx, (src, tgt) in (enumerate(val_iter)):\n",
    "#         print(idx)\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,\n",
    "                                  src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "        tgt_out = tgt[1:,:]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "    return losses / len(val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a130e410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train loss: 5.902, val loss : 4.953 Epoch time = 92.427s\n",
      "Epoch: 2, Train loss: 4.562, val loss : 4.101 Epoch time = 94.268s\n",
      "Epoch: 3, Train loss: 3.878, val loss : 3.419 Epoch time = 96.235s\n",
      "Epoch: 4, Train loss: 3.281, val loss : 2.775 Epoch time = 95.642s\n",
      "Epoch: 5, Train loss: 2.791, val loss : 2.318 Epoch time = 95.767s\n",
      "Epoch: 6, Train loss: 2.421, val loss : 1.959 Epoch time = 95.708s\n",
      "Epoch: 7, Train loss: 2.140, val loss : 1.697 Epoch time = 94.254s\n",
      "Epoch: 8, Train loss: 1.920, val loss : 1.497 Epoch time = 94.566s\n",
      "Epoch: 9, Train loss: 1.744, val loss : 1.339 Epoch time = 92.112s\n",
      "Epoch: 10, Train loss: 1.598, val loss : 1.190 Epoch time = 91.463s\n",
      "Epoch: 11, Train loss: 1.474, val loss : 1.085 Epoch time = 91.308s\n",
      "Epoch: 12, Train loss: 1.367, val loss : 0.992 Epoch time = 94.766s\n",
      "Epoch: 13, Train loss: 1.277, val loss : 0.911 Epoch time = 95.710s\n",
      "Epoch: 14, Train loss: 1.197, val loss : 0.825 Epoch time = 95.715s\n",
      "Epoch: 15, Train loss: 1.123, val loss : 0.766 Epoch time = 94.334s\n",
      "Epoch: 16, Train loss: 1.056, val loss : 0.704 Epoch time = 92.875s\n",
      "Epoch: 17, Train loss: 0.995, val loss : 0.640 Epoch time = 93.336s\n",
      "Epoch: 18, Train loss: 0.936, val loss : 0.592 Epoch time = 96.717s\n",
      "Epoch: 19, Train loss: 0.884, val loss : 0.547 Epoch time = 96.176s\n",
      "Epoch: 20, Train loss: 0.835, val loss : 0.505 Epoch time = 95.112s\n",
      "Epoch: 21, Train loss: 0.790, val loss : 0.463 Epoch time = 95.165s\n",
      "Epoch: 22, Train loss: 0.746, val loss : 0.428 Epoch time = 94.035s\n",
      "Epoch: 23, Train loss: 0.706, val loss : 0.397 Epoch time = 94.886s\n",
      "Epoch: 24, Train loss: 0.669, val loss : 0.364 Epoch time = 94.424s\n",
      "Epoch: 25, Train loss: 0.635, val loss : 0.340 Epoch time = 98.706s\n",
      "Epoch: 26, Train loss: 0.604, val loss : 0.315 Epoch time = 100.892s\n",
      "Epoch: 27, Train loss: 0.575, val loss : 0.295 Epoch time = 99.225s\n",
      "Epoch: 28, Train loss: 0.546, val loss : 0.272 Epoch time = 97.442s\n",
      "Epoch: 29, Train loss: 0.521, val loss : 0.252 Epoch time = 100.247s\n",
      "Epoch: 30, Train loss: 0.497, val loss : 0.239 Epoch time = 101.294s\n",
      "Epoch: 31, Train loss: 0.475, val loss : 0.223 Epoch time = 100.373s\n",
      "Epoch: 32, Train loss: 0.456, val loss : 0.209 Epoch time = 95.986s\n",
      "Epoch: 33, Train loss: 0.437, val loss : 0.199 Epoch time = 95.610s\n",
      "Epoch: 34, Train loss: 0.419, val loss : 0.186 Epoch time = 95.200s\n",
      "Epoch: 35, Train loss: 0.403, val loss : 0.182 Epoch time = 95.051s\n",
      "Epoch: 36, Train loss: 0.389, val loss : 0.169 Epoch time = 94.236s\n",
      "Epoch: 37, Train loss: 0.374, val loss : 0.161 Epoch time = 95.393s\n",
      "Epoch: 38, Train loss: 0.360, val loss : 0.155 Epoch time = 97.576s\n",
      "Epoch: 39, Train loss: 0.349, val loss : 0.147 Epoch time = 97.247s\n",
      "Epoch: 40, Train loss: 0.338, val loss : 0.142 Epoch time = 95.199s\n",
      "Epoch: 41, Train loss: 0.328, val loss : 0.135 Epoch time = 94.326s\n",
      "Epoch: 42, Train loss: 0.318, val loss : 0.132 Epoch time = 94.774s\n",
      "Epoch: 43, Train loss: 0.310, val loss : 0.126 Epoch time = 95.571s\n",
      "Epoch: 44, Train loss: 0.301, val loss : 0.121 Epoch time = 92.664s\n",
      "Epoch: 45, Train loss: 0.293, val loss : 0.119 Epoch time = 92.231s\n",
      "Epoch: 46, Train loss: 0.288, val loss : 0.115 Epoch time = 97.869s\n",
      "Epoch: 47, Train loss: 0.280, val loss : 0.113 Epoch time = 94.387s\n",
      "Epoch: 48, Train loss: 0.276, val loss : 0.110 Epoch time = 96.789s\n",
      "Epoch: 49, Train loss: 0.269, val loss : 0.105 Epoch time = 94.754s\n",
      "Epoch: 50, Train loss: 0.264, val loss : 0.106 Epoch time = 98.684s\n",
      "Epoch: 51, Train loss: 0.260, val loss : 0.103 Epoch time = 95.782s\n",
      "Epoch: 52, Train loss: 0.255, val loss : 0.100 Epoch time = 96.259s\n",
      "Epoch: 53, Train loss: 0.251, val loss : 0.099 Epoch time = 96.554s\n",
      "Epoch: 54, Train loss: 0.248, val loss : 0.096 Epoch time = 93.024s\n",
      "Epoch: 55, Train loss: 0.243, val loss : 0.096 Epoch time = 91.046s\n",
      "Epoch: 56, Train loss: 0.239, val loss : 0.096 Epoch time = 91.117s\n",
      "Epoch: 57, Train loss: 0.236, val loss : 0.092 Epoch time = 94.255s\n",
      "Epoch: 58, Train loss: 0.233, val loss : 0.089 Epoch time = 91.098s\n",
      "Epoch: 59, Train loss: 0.230, val loss : 0.089 Epoch time = 91.219s\n",
      "Epoch: 60, Train loss: 0.227, val loss : 0.089 Epoch time = 91.681s\n",
      "Epoch: 61, Train loss: 0.225, val loss : 0.089 Epoch time = 91.311s\n",
      "Epoch: 62, Train loss: 0.222, val loss : 0.086 Epoch time = 91.335s\n",
      "Epoch: 63, Train loss: 0.221, val loss : 0.085 Epoch time = 91.346s\n",
      "Epoch: 64, Train loss: 0.216, val loss : 0.082 Epoch time = 91.144s\n",
      "Epoch: 65, Train loss: 0.213, val loss : 0.082 Epoch time = 91.191s\n",
      "Epoch: 66, Train loss: 0.212, val loss : 0.081 Epoch time = 91.322s\n",
      "Epoch: 67, Train loss: 0.210, val loss : 0.082 Epoch time = 91.268s\n",
      "Epoch: 68, Train loss: 0.210, val loss : 0.080 Epoch time = 91.162s\n",
      "Epoch: 69, Train loss: 0.206, val loss : 0.079 Epoch time = 91.253s\n",
      "Epoch: 70, Train loss: 0.206, val loss : 0.080 Epoch time = 90.986s\n",
      "Epoch: 71, Train loss: 0.203, val loss : 0.077 Epoch time = 90.801s\n",
      "Epoch: 72, Train loss: 0.201, val loss : 0.077 Epoch time = 91.516s\n",
      "Epoch: 73, Train loss: 0.201, val loss : 0.078 Epoch time = 91.166s\n",
      "Epoch: 74, Train loss: 0.198, val loss : 0.076 Epoch time = 91.133s\n",
      "Epoch: 75, Train loss: 0.197, val loss : 0.076 Epoch time = 91.235s\n",
      "Epoch: 76, Train loss: 0.196, val loss : 0.075 Epoch time = 91.082s\n",
      "Epoch: 77, Train loss: 0.195, val loss : 0.075 Epoch time = 91.084s\n",
      "Epoch: 78, Train loss: 0.193, val loss : 0.073 Epoch time = 90.893s\n",
      "Epoch: 79, Train loss: 0.191, val loss : 0.072 Epoch time = 91.143s\n",
      "Epoch: 80, Train loss: 0.191, val loss : 0.073 Epoch time = 90.986s\n",
      "Epoch: 81, Train loss: 0.189, val loss : 0.073 Epoch time = 91.155s\n",
      "Epoch: 82, Train loss: 0.187, val loss : 0.071 Epoch time = 91.103s\n",
      "Epoch: 83, Train loss: 0.187, val loss : 0.072 Epoch time = 91.073s\n",
      "Epoch: 84, Train loss: 0.185, val loss : 0.071 Epoch time = 91.036s\n",
      "Epoch: 85, Train loss: 0.185, val loss : 0.069 Epoch time = 91.280s\n",
      "Epoch: 86, Train loss: 0.183, val loss : 0.071 Epoch time = 91.175s\n",
      "Epoch: 87, Train loss: 0.182, val loss : 0.069 Epoch time = 91.159s\n",
      "Epoch: 88, Train loss: 0.181, val loss : 0.069 Epoch time = 91.293s\n",
      "Epoch: 89, Train loss: 0.179, val loss : 0.071 Epoch time = 91.230s\n",
      "Epoch: 90, Train loss: 0.179, val loss : 0.067 Epoch time = 91.473s\n",
      "Epoch: 91, Train loss: 0.178, val loss : 0.068 Epoch time = 91.236s\n",
      "Epoch: 92, Train loss: 0.177, val loss : 0.068 Epoch time = 91.415s\n",
      "Epoch: 93, Train loss: 0.175, val loss : 0.066 Epoch time = 91.118s\n",
      "Epoch: 94, Train loss: 0.174, val loss : 0.067 Epoch time = 91.162s\n",
      "Epoch: 95, Train loss: 0.174, val loss : 0.068 Epoch time = 91.547s\n",
      "Epoch: 96, Train loss: 0.173, val loss : 0.065 Epoch time = 91.387s\n",
      "Epoch: 97, Train loss: 0.172, val loss : 0.068 Epoch time = 91.484s\n",
      "Epoch: 98, Train loss: 0.171, val loss : 0.067 Epoch time = 91.823s\n",
      "Epoch: 99, Train loss: 0.170, val loss : 0.065 Epoch time = 91.489s\n",
      "Epoch: 100, Train loss: 0.169, val loss : 0.064 Epoch time = 91.289s\n",
      "Epoch: 101, Train loss: 0.168, val loss : 0.065 Epoch time = 91.605s\n",
      "Epoch: 102, Train loss: 0.169, val loss : 0.066 Epoch time = 91.697s\n",
      "Epoch: 103, Train loss: 0.167, val loss : 0.063 Epoch time = 91.533s\n",
      "Epoch: 104, Train loss: 0.166, val loss : 0.064 Epoch time = 91.435s\n",
      "Epoch: 105, Train loss: 0.164, val loss : 0.064 Epoch time = 91.044s\n",
      "Epoch: 106, Train loss: 0.165, val loss : 0.066 Epoch time = 91.159s\n",
      "Epoch: 107, Train loss: 0.166, val loss : 0.065 Epoch time = 91.685s\n",
      "Epoch: 108, Train loss: 0.164, val loss : 0.063 Epoch time = 91.128s\n",
      "Epoch: 109, Train loss: 0.163, val loss : 0.065 Epoch time = 90.848s\n",
      "Epoch: 110, Train loss: 0.163, val loss : 0.064 Epoch time = 90.938s\n",
      "Epoch: 111, Train loss: 0.163, val loss : 0.061 Epoch time = 90.712s\n",
      "Epoch: 112, Train loss: 0.160, val loss : 0.062 Epoch time = 91.553s\n",
      "Epoch: 113, Train loss: 0.160, val loss : 0.064 Epoch time = 91.215s\n",
      "Epoch: 114, Train loss: 0.159, val loss : 0.063 Epoch time = 91.132s\n",
      "Epoch: 115, Train loss: 0.159, val loss : 0.064 Epoch time = 90.962s\n",
      "Epoch: 116, Train loss: 0.160, val loss : 0.063 Epoch time = 91.537s\n",
      "Epoch: 117, Train loss: 0.159, val loss : 0.062 Epoch time = 91.736s\n",
      "Epoch: 118, Train loss: 0.158, val loss : 0.060 Epoch time = 91.591s\n",
      "Epoch: 119, Train loss: 0.157, val loss : 0.060 Epoch time = 91.080s\n",
      "Epoch: 120, Train loss: 0.157, val loss : 0.062 Epoch time = 91.222s\n",
      "Epoch: 121, Train loss: 0.158, val loss : 0.060 Epoch time = 91.385s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 122, Train loss: 0.155, val loss : 0.062 Epoch time = 91.213s\n",
      "Epoch: 123, Train loss: 0.155, val loss : 0.061 Epoch time = 91.315s\n",
      "Epoch: 124, Train loss: 0.154, val loss : 0.061 Epoch time = 91.263s\n",
      "Epoch: 125, Train loss: 0.154, val loss : 0.059 Epoch time = 91.551s\n",
      "Epoch: 126, Train loss: 0.153, val loss : 0.063 Epoch time = 91.151s\n",
      "Epoch: 127, Train loss: 0.155, val loss : 0.061 Epoch time = 91.224s\n",
      "Epoch: 128, Train loss: 0.152, val loss : 0.063 Epoch time = 91.076s\n",
      "Epoch: 129, Train loss: 0.153, val loss : 0.061 Epoch time = 91.271s\n",
      "Epoch: 130, Train loss: 0.152, val loss : 0.057 Epoch time = 91.052s\n",
      "Epoch: 131, Train loss: 0.150, val loss : 0.059 Epoch time = 90.998s\n",
      "Epoch: 132, Train loss: 0.152, val loss : 0.060 Epoch time = 91.008s\n",
      "Epoch: 133, Train loss: 0.150, val loss : 0.061 Epoch time = 91.007s\n",
      "Epoch: 134, Train loss: 0.151, val loss : 0.062 Epoch time = 90.948s\n",
      "Epoch: 135, Train loss: 0.150, val loss : 0.059 Epoch time = 91.086s\n",
      "Epoch: 136, Train loss: 0.150, val loss : 0.058 Epoch time = 91.382s\n",
      "Epoch: 137, Train loss: 0.150, val loss : 0.057 Epoch time = 91.115s\n",
      "Epoch: 138, Train loss: 0.148, val loss : 0.059 Epoch time = 91.349s\n",
      "Epoch: 139, Train loss: 0.148, val loss : 0.060 Epoch time = 91.068s\n",
      "Epoch: 140, Train loss: 0.148, val loss : 0.060 Epoch time = 91.049s\n",
      "Epoch: 141, Train loss: 0.148, val loss : 0.060 Epoch time = 90.939s\n",
      "Epoch: 142, Train loss: 0.146, val loss : 0.062 Epoch time = 91.194s\n",
      "Epoch: 143, Train loss: 0.148, val loss : 0.058 Epoch time = 91.381s\n",
      "Epoch: 144, Train loss: 0.145, val loss : 0.061 Epoch time = 91.277s\n",
      "Epoch: 145, Train loss: 0.145, val loss : 0.058 Epoch time = 91.076s\n",
      "Epoch: 146, Train loss: 0.146, val loss : 0.057 Epoch time = 91.162s\n",
      "Epoch: 147, Train loss: 0.145, val loss : 0.059 Epoch time = 91.288s\n",
      "Epoch: 148, Train loss: 0.146, val loss : 0.061 Epoch time = 91.681s\n",
      "Epoch: 149, Train loss: 0.145, val loss : 0.062 Epoch time = 91.859s\n",
      "Epoch: 150, Train loss: 0.144, val loss : 0.059 Epoch time = 91.289s\n",
      "Epoch: 151, Train loss: 0.145, val loss : 0.061 Epoch time = 91.230s\n",
      "Epoch: 152, Train loss: 0.145, val loss : 0.058 Epoch time = 91.270s\n",
      "Epoch: 153, Train loss: 0.143, val loss : 0.059 Epoch time = 91.469s\n",
      "Epoch: 154, Train loss: 0.142, val loss : 0.056 Epoch time = 91.024s\n",
      "Epoch: 155, Train loss: 0.144, val loss : 0.056 Epoch time = 91.591s\n",
      "Epoch: 156, Train loss: 0.141, val loss : 0.059 Epoch time = 91.137s\n",
      "Epoch: 157, Train loss: 0.141, val loss : 0.059 Epoch time = 91.185s\n",
      "Epoch: 158, Train loss: 0.142, val loss : 0.060 Epoch time = 90.774s\n",
      "Epoch: 159, Train loss: 0.141, val loss : 0.061 Epoch time = 90.730s\n",
      "Epoch: 160, Train loss: 0.141, val loss : 0.058 Epoch time = 90.884s\n",
      "Epoch: 161, Train loss: 0.141, val loss : 0.059 Epoch time = 91.362s\n",
      "Epoch: 162, Train loss: 0.141, val loss : 0.058 Epoch time = 91.536s\n",
      "Epoch: 163, Train loss: 0.139, val loss : 0.059 Epoch time = 91.210s\n",
      "Epoch: 164, Train loss: 0.139, val loss : 0.054 Epoch time = 91.079s\n",
      "Epoch: 165, Train loss: 0.139, val loss : 0.056 Epoch time = 91.224s\n",
      "Epoch: 166, Train loss: 0.139, val loss : 0.056 Epoch time = 91.262s\n",
      "Epoch: 167, Train loss: 0.139, val loss : 0.055 Epoch time = 91.257s\n",
      "Epoch: 168, Train loss: 0.139, val loss : 0.057 Epoch time = 91.190s\n",
      "Epoch: 169, Train loss: 0.138, val loss : 0.058 Epoch time = 91.217s\n",
      "Epoch: 170, Train loss: 0.138, val loss : 0.057 Epoch time = 91.041s\n",
      "Epoch: 171, Train loss: 0.138, val loss : 0.056 Epoch time = 91.449s\n",
      "Epoch: 172, Train loss: 0.137, val loss : 0.055 Epoch time = 91.753s\n",
      "Epoch: 173, Train loss: 0.139, val loss : 0.058 Epoch time = 91.297s\n",
      "Epoch: 174, Train loss: 0.137, val loss : 0.055 Epoch time = 91.751s\n",
      "Epoch: 175, Train loss: 0.136, val loss : 0.055 Epoch time = 91.277s\n",
      "Epoch: 176, Train loss: 0.136, val loss : 0.057 Epoch time = 91.448s\n",
      "Epoch: 177, Train loss: 0.136, val loss : 0.054 Epoch time = 91.298s\n",
      "Epoch: 178, Train loss: 0.137, val loss : 0.055 Epoch time = 91.179s\n",
      "Epoch: 179, Train loss: 0.136, val loss : 0.056 Epoch time = 91.402s\n",
      "Epoch: 180, Train loss: 0.135, val loss : 0.060 Epoch time = 91.074s\n",
      "Epoch: 181, Train loss: 0.138, val loss : 0.061 Epoch time = 91.040s\n",
      "Epoch: 182, Train loss: 0.135, val loss : 0.059 Epoch time = 91.323s\n",
      "Epoch: 183, Train loss: 0.135, val loss : 0.055 Epoch time = 91.196s\n",
      "Epoch: 184, Train loss: 0.135, val loss : 0.056 Epoch time = 91.110s\n",
      "Epoch: 185, Train loss: 0.134, val loss : 0.056 Epoch time = 91.272s\n",
      "Epoch: 186, Train loss: 0.134, val loss : 0.053 Epoch time = 91.140s\n",
      "Epoch: 187, Train loss: 0.135, val loss : 0.055 Epoch time = 91.237s\n",
      "Epoch: 188, Train loss: 0.134, val loss : 0.055 Epoch time = 91.290s\n",
      "Epoch: 189, Train loss: 0.134, val loss : 0.057 Epoch time = 91.314s\n",
      "Epoch: 190, Train loss: 0.134, val loss : 0.057 Epoch time = 91.534s\n",
      "Epoch: 191, Train loss: 0.134, val loss : 0.055 Epoch time = 91.287s\n",
      "Epoch: 192, Train loss: 0.133, val loss : 0.056 Epoch time = 91.237s\n",
      "Epoch: 193, Train loss: 0.133, val loss : 0.055 Epoch time = 90.797s\n",
      "Epoch: 194, Train loss: 0.133, val loss : 0.058 Epoch time = 90.816s\n",
      "Epoch: 195, Train loss: 0.133, val loss : 0.059 Epoch time = 90.924s\n",
      "Epoch: 196, Train loss: 0.133, val loss : 0.055 Epoch time = 90.826s\n",
      "Epoch: 197, Train loss: 0.132, val loss : 0.053 Epoch time = 91.084s\n",
      "Epoch: 198, Train loss: 0.131, val loss : 0.057 Epoch time = 91.170s\n",
      "Epoch: 199, Train loss: 0.132, val loss : 0.055 Epoch time = 91.118s\n",
      "Epoch: 200, Train loss: 0.132, val loss : 0.055 Epoch time = 91.038s\n",
      "Epoch: 201, Train loss: 0.132, val loss : 0.056 Epoch time = 91.222s\n",
      "Epoch: 202, Train loss: 0.132, val loss : 0.057 Epoch time = 91.007s\n",
      "Epoch: 203, Train loss: 0.130, val loss : 0.054 Epoch time = 91.038s\n",
      "Epoch: 204, Train loss: 0.132, val loss : 0.054 Epoch time = 91.075s\n",
      "Epoch: 205, Train loss: 0.131, val loss : 0.054 Epoch time = 91.053s\n",
      "Epoch: 206, Train loss: 0.131, val loss : 0.056 Epoch time = 91.162s\n",
      "Epoch: 207, Train loss: 0.131, val loss : 0.055 Epoch time = 90.966s\n",
      "Epoch: 208, Train loss: 0.131, val loss : 0.059 Epoch time = 90.978s\n",
      "Epoch: 209, Train loss: 0.130, val loss : 0.058 Epoch time = 91.025s\n",
      "Epoch: 210, Train loss: 0.130, val loss : 0.057 Epoch time = 90.903s\n",
      "Epoch: 211, Train loss: 0.130, val loss : 0.058 Epoch time = 90.927s\n",
      "Epoch: 212, Train loss: 0.130, val loss : 0.055 Epoch time = 90.747s\n",
      "Epoch: 213, Train loss: 0.131, val loss : 0.057 Epoch time = 91.119s\n",
      "Epoch: 214, Train loss: 0.129, val loss : 0.055 Epoch time = 90.935s\n",
      "Epoch: 215, Train loss: 0.130, val loss : 0.053 Epoch time = 90.772s\n",
      "Epoch: 216, Train loss: 0.129, val loss : 0.053 Epoch time = 90.740s\n",
      "Epoch: 217, Train loss: 0.129, val loss : 0.056 Epoch time = 90.672s\n",
      "Epoch: 218, Train loss: 0.130, val loss : 0.054 Epoch time = 91.620s\n",
      "Epoch: 219, Train loss: 0.128, val loss : 0.059 Epoch time = 91.390s\n",
      "Epoch: 220, Train loss: 0.130, val loss : 0.053 Epoch time = 91.673s\n",
      "Epoch: 221, Train loss: 0.130, val loss : 0.055 Epoch time = 91.222s\n",
      "Epoch: 222, Train loss: 0.129, val loss : 0.056 Epoch time = 91.380s\n",
      "Epoch: 223, Train loss: 0.129, val loss : 0.055 Epoch time = 91.241s\n",
      "Epoch: 224, Train loss: 0.130, val loss : 0.052 Epoch time = 91.722s\n",
      "Epoch: 225, Train loss: 0.128, val loss : 0.054 Epoch time = 91.422s\n",
      "Epoch: 226, Train loss: 0.128, val loss : 0.054 Epoch time = 91.396s\n",
      "Epoch: 227, Train loss: 0.128, val loss : 0.054 Epoch time = 91.054s\n",
      "Epoch: 228, Train loss: 0.127, val loss : 0.057 Epoch time = 91.181s\n",
      "Epoch: 229, Train loss: 0.129, val loss : 0.053 Epoch time = 91.237s\n",
      "Epoch: 230, Train loss: 0.128, val loss : 0.055 Epoch time = 91.192s\n",
      "Epoch: 231, Train loss: 0.126, val loss : 0.055 Epoch time = 91.993s\n",
      "Epoch: 232, Train loss: 0.128, val loss : 0.057 Epoch time = 92.891s\n",
      "Epoch: 233, Train loss: 0.128, val loss : 0.055 Epoch time = 91.067s\n",
      "Epoch: 234, Train loss: 0.126, val loss : 0.053 Epoch time = 90.952s\n",
      "Epoch: 235, Train loss: 0.127, val loss : 0.054 Epoch time = 91.441s\n",
      "Epoch: 236, Train loss: 0.127, val loss : 0.054 Epoch time = 91.345s\n",
      "Epoch: 237, Train loss: 0.127, val loss : 0.055 Epoch time = 91.444s\n",
      "Epoch: 238, Train loss: 0.127, val loss : 0.055 Epoch time = 90.940s\n",
      "Epoch: 239, Train loss: 0.127, val loss : 0.055 Epoch time = 91.173s\n",
      "Epoch: 240, Train loss: 0.126, val loss : 0.055 Epoch time = 91.272s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 241, Train loss: 0.125, val loss : 0.053 Epoch time = 91.224s\n",
      "Epoch: 242, Train loss: 0.125, val loss : 0.055 Epoch time = 91.206s\n",
      "Epoch: 243, Train loss: 0.126, val loss : 0.056 Epoch time = 90.965s\n",
      "Epoch: 244, Train loss: 0.125, val loss : 0.054 Epoch time = 91.225s\n",
      "Epoch: 245, Train loss: 0.126, val loss : 0.053 Epoch time = 90.985s\n",
      "Epoch: 246, Train loss: 0.126, val loss : 0.053 Epoch time = 91.125s\n",
      "Epoch: 247, Train loss: 0.126, val loss : 0.052 Epoch time = 91.171s\n",
      "Epoch: 248, Train loss: 0.125, val loss : 0.051 Epoch time = 91.303s\n",
      "Epoch: 249, Train loss: 0.126, val loss : 0.052 Epoch time = 91.259s\n",
      "Epoch: 250, Train loss: 0.125, val loss : 0.054 Epoch time = 91.279s\n",
      "Epoch: 251, Train loss: 0.125, val loss : 0.053 Epoch time = 91.248s\n",
      "Epoch: 252, Train loss: 0.125, val loss : 0.058 Epoch time = 91.271s\n",
      "Epoch: 253, Train loss: 0.125, val loss : 0.055 Epoch time = 91.964s\n",
      "Epoch: 254, Train loss: 0.125, val loss : 0.054 Epoch time = 91.298s\n",
      "Epoch: 255, Train loss: 0.124, val loss : 0.054 Epoch time = 91.277s\n",
      "Epoch: 256, Train loss: 0.125, val loss : 0.056 Epoch time = 91.065s\n",
      "Epoch: 257, Train loss: 0.123, val loss : 0.055 Epoch time = 91.105s\n",
      "Epoch: 258, Train loss: 0.125, val loss : 0.054 Epoch time = 91.317s\n",
      "Epoch: 259, Train loss: 0.125, val loss : 0.054 Epoch time = 91.793s\n",
      "Epoch: 260, Train loss: 0.124, val loss : 0.053 Epoch time = 91.162s\n",
      "Epoch: 261, Train loss: 0.124, val loss : 0.053 Epoch time = 91.118s\n",
      "Epoch: 262, Train loss: 0.125, val loss : 0.051 Epoch time = 91.217s\n",
      "Epoch: 263, Train loss: 0.123, val loss : 0.054 Epoch time = 91.070s\n",
      "Epoch: 264, Train loss: 0.123, val loss : 0.058 Epoch time = 91.259s\n",
      "Epoch: 265, Train loss: 0.124, val loss : 0.056 Epoch time = 91.125s\n",
      "Epoch: 266, Train loss: 0.123, val loss : 0.053 Epoch time = 91.304s\n",
      "Epoch: 267, Train loss: 0.124, val loss : 0.056 Epoch time = 91.364s\n",
      "Epoch: 268, Train loss: 0.123, val loss : 0.051 Epoch time = 91.171s\n",
      "Epoch: 269, Train loss: 0.123, val loss : 0.054 Epoch time = 90.944s\n",
      "Epoch: 270, Train loss: 0.122, val loss : 0.052 Epoch time = 90.821s\n",
      "Epoch: 271, Train loss: 0.123, val loss : 0.052 Epoch time = 91.348s\n",
      "Epoch: 272, Train loss: 0.123, val loss : 0.052 Epoch time = 91.470s\n",
      "Epoch: 273, Train loss: 0.123, val loss : 0.053 Epoch time = 91.487s\n",
      "Epoch: 274, Train loss: 0.123, val loss : 0.054 Epoch time = 91.366s\n",
      "Epoch: 275, Train loss: 0.124, val loss : 0.051 Epoch time = 91.108s\n",
      "Epoch: 276, Train loss: 0.121, val loss : 0.056 Epoch time = 91.208s\n",
      "Epoch: 277, Train loss: 0.123, val loss : 0.057 Epoch time = 91.115s\n",
      "Epoch: 278, Train loss: 0.122, val loss : 0.053 Epoch time = 91.193s\n",
      "Epoch: 279, Train loss: 0.122, val loss : 0.054 Epoch time = 91.322s\n",
      "Epoch: 280, Train loss: 0.122, val loss : 0.054 Epoch time = 91.418s\n",
      "Epoch: 281, Train loss: 0.123, val loss : 0.052 Epoch time = 91.375s\n",
      "Epoch: 282, Train loss: 0.121, val loss : 0.055 Epoch time = 91.108s\n",
      "Epoch: 283, Train loss: 0.123, val loss : 0.054 Epoch time = 91.294s\n",
      "Epoch: 284, Train loss: 0.121, val loss : 0.051 Epoch time = 91.341s\n",
      "Epoch: 285, Train loss: 0.122, val loss : 0.051 Epoch time = 91.184s\n",
      "Epoch: 286, Train loss: 0.121, val loss : 0.055 Epoch time = 91.231s\n",
      "Epoch: 287, Train loss: 0.122, val loss : 0.054 Epoch time = 91.239s\n",
      "Epoch: 288, Train loss: 0.121, val loss : 0.052 Epoch time = 91.688s\n",
      "Epoch: 289, Train loss: 0.121, val loss : 0.053 Epoch time = 91.205s\n",
      "Epoch: 290, Train loss: 0.122, val loss : 0.051 Epoch time = 91.470s\n",
      "Epoch: 291, Train loss: 0.122, val loss : 0.055 Epoch time = 90.825s\n",
      "Epoch: 292, Train loss: 0.121, val loss : 0.052 Epoch time = 91.290s\n",
      "Epoch: 293, Train loss: 0.122, val loss : 0.051 Epoch time = 91.395s\n",
      "Epoch: 294, Train loss: 0.122, val loss : 0.053 Epoch time = 91.226s\n",
      "Epoch: 295, Train loss: 0.119, val loss : 0.054 Epoch time = 91.208s\n",
      "Epoch: 296, Train loss: 0.121, val loss : 0.052 Epoch time = 91.485s\n",
      "Epoch: 297, Train loss: 0.121, val loss : 0.052 Epoch time = 91.279s\n",
      "Epoch: 298, Train loss: 0.122, val loss : 0.056 Epoch time = 91.367s\n",
      "Epoch: 299, Train loss: 0.122, val loss : 0.053 Epoch time = 91.424s\n",
      "Epoch: 300, Train loss: 0.121, val loss : 0.055 Epoch time = 91.254s\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    train_loss = train_epoch(transformer, train_iter, optimizer)\n",
    "#     if epoch % 5 == 0:\n",
    "    val_loss = evaluate(transformer, val_iter)\n",
    "    end_time = time.time()\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, val loss : {val_loss:.3f} \"\n",
    "          f\"Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "\n",
    "        \n",
    "    # save model + checkpoint to resume training later\n",
    "    torch.save({\n",
    "      'epoch': NUM_EPOCHS,\n",
    "      'model_state_dict': transformer.state_dict(),\n",
    "      'optimizer_state_dict': optimizer.state_dict(),\n",
    "      'loss': train_loss,\n",
    "      }, 'model/model_checkpoint.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bcc050c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "83fa543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(device)\n",
    "    src_mask = src_mask.to(device)\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(device)\n",
    "        memory_mask = torch.zeros(ys.shape[0], memory.shape[0]).to(device).type(torch.bool)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                                    .type(torch.bool)).to(device)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.item()\n",
    "        ys = torch.cat([ys,torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "def translate(model, src, src_vocab, tgt_vocab, src_tokenizer):\n",
    "    model.eval()\n",
    "    tokens = [BOS_IDX] + [src_vocab.get_stoi()[tok] for tok in src_tokenizer.encode(src, out_type=str)]+ [EOS_IDX]\n",
    "    num_tokens = len(tokens)\n",
    "    src = (torch.LongTensor(tokens).reshape(num_tokens, 1) )\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    p_text = \" \".join([tgt_vocab.get_itos()[tok] for tok in tgt_tokens]).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
    "    pts = \" \".join(list(map(lambda x : x , p_text.replace(\" \", \"\").split(\"▁\"))))\n",
    "    return pts.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6a9cfe19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : বাকেরগঞ্জ জেলা নামটি ১৭৯৭ থেকে ১৯৯৩ সালপর্যন্ত ছিল\n",
      "prediction: The name Bakerganj district was from 1797 to 1993\n"
     ]
    }
   ],
   "source": [
    "# for i in data[:10]:\n",
    "text = \"বাকেরগঞ্জ জেলা নামটি ১৭৯৭ থেকে ১৯৯৩ সালপর্যন্ত ছিল\"\n",
    "pre = translate(transformer, text, bn_vocab, en_vocab, bn_tokenizer)\n",
    "print(f\"input : {text}\")\n",
    "print(f\"prediction: {pre}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "1b9a650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# itos = ja_vocab.itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b0285218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# open a file, where you want to store the data\n",
    "file = open('model/bn_vocab.pkl', 'wb')\n",
    "# dump information to that file\n",
    "pickle.dump(bn_vocab, file)\n",
    "file.close()\n",
    "file = open('model/en_vocab.pkl', 'wb')\n",
    "pickle.dump(en_vocab, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d5d2adae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model + checkpoint to resume training later\n",
    "torch.save({\n",
    "  'epoch': NUM_EPOCHS,\n",
    "  'model_state_dict': transformer.state_dict(),\n",
    "  'optimizer_state_dict': optimizer.state_dict(),\n",
    "  'loss': train_loss,\n",
    "  }, 'model/model_checkpoint.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daada9c8",
   "metadata": {},
   "source": [
    "## Inference\n",
    "Here the inference script after load sentencepice train tokenizer model, vocal and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e4054145",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ac2a172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_tokenizer = spm.SentencePieceProcessor(model_file='model/bn_model.model')\n",
    "en_tokenizer = spm.SentencePieceProcessor(model_file='model/en_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9d3e70f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('model/bn_vocab.pkl', 'rb')\n",
    "bn_vocal = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bdaf63e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('model/en_vocab.pkl', 'rb')\n",
    "en_vocal = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "164aba80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqTransformer(\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (generator): Linear(in_features=512, out_features=30508, bias=True)\n",
       "  (src_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(50428, 512)\n",
       "  )\n",
       "  (tgt_tok_emb): TokenEmbedding(\n",
       "    (embedding): Embedding(30508, 512)\n",
       "  )\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"model/model_checkpoint.pt\"\n",
    "\n",
    "model = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS,\n",
    "                                 EMB_SIZE, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE,\n",
    "                                 FFN_HID_DIM)\n",
    "model.to(device)\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "f7ffcbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(device)\n",
    "    src_mask = src_mask.to(device)\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(device)\n",
    "        memory_mask = torch.zeros(ys.shape[0], memory.shape[0]).to(device).type(torch.bool)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                                    .type(torch.bool)).to(device)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.item()\n",
    "        ys = torch.cat([ys,torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "def translate(model, src, src_vocab, tgt_vocab, src_tokenizer):\n",
    "#     model.eval()\n",
    "    tokens = [BOS_IDX] + [src_vocab.get_stoi()[tok] for tok in src_tokenizer.encode(src, out_type=str)]+ [EOS_IDX]\n",
    "    num_tokens = len(tokens)\n",
    "    src = (torch.LongTensor(tokens).reshape(num_tokens, 1) )\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    p_text = \" \".join([tgt_vocab.get_itos()[tok] for tok in tgt_tokens]).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
    "    pts = \" \".join(list(map(lambda x : x , p_text.replace(\" \", \"\").split(\"▁\"))))\n",
    "    return pts.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "544fa57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : বাকেরগঞ্জ জেলা নামটি ১৭৯৭ থেকে ১৯৯৩ সালপর্যন্ত ছিল\n",
      "Ground Truth : The name Bakerganj district was from 1797 to 1993 \n",
      "prediction: The name Bakerganj district was from 1797 to 1993\n",
      "================================\n",
      "input : জেলা সদর বরিশালের নামে বিভাগের নামকরণ করা হয়\n",
      "Ground Truth : The division was named after the district headquarters Barisal \n",
      "prediction: The division was named after the district headquarters Barisal\n",
      "================================\n",
      "input : বিবিধ  বাকেরগঞ্জ উপজেলার প্রায় ৮০ভাগের পেশাই চাষাবাদ\n",
      "Ground Truth : Miscellaneous occupations of about 80 per cent of Bakerganj upazila \n",
      "prediction: Miscellaneous occupations of about 80 per cent of Bakerganj upazila\n",
      "================================\n",
      "input : এই উপজেলার প্রায় ৮০ ভাগই ইসলাম ধর্ম অনুসারি\n",
      "Ground Truth : About 80 percent of this upazila is Islamic \n",
      "prediction: About 80 percent of this upazila is Islamic\n",
      "================================\n",
      "input : বাকি ২০ভাগ হিন্দু এবং খ্রীষ্টান\n",
      "Ground Truth : The remaining 20 percent are Hindus and Christians \n",
      "prediction: The remaining 20 percent are Hindus and Christians\n",
      "================================\n",
      "input : এই উপজেলায় ১টি সরকারি কলেজ রয়েছে\n",
      "Ground Truth : There is 1 government college in this upazila \n",
      "prediction: There is 1 government college in this upazila\n",
      "================================\n",
      "input : বাকেরগঞ্জ সরকারি কলেজ\n",
      "Ground Truth : Bakerganj Government College \n",
      "prediction: Bakerganj Government College\n",
      "================================\n",
      "input : তালু  মুখগহ্বর  তালু মুখগহ্বরের ছাদ\n",
      "Ground Truth : The palate is the roof of the palate \n",
      "prediction: The palate is the roof of the palate\n",
      "================================\n",
      "input : ২০০৮ ২০০৮ গ্রেগরীয় বর্ষপঞ্জীর একটি অধিবর্ষ\n",
      "Ground Truth : 2006 is a leap year in the Gregorian calendar \n",
      "prediction: 2006 is a leap year in the Gregorian calendar\n",
      "================================\n",
      "input : ১৯০০ ১৯০০ গ্রেগরীয় বর্ষপঞ্জীর একটি সাধারণ বছর\n",
      "Ground Truth : 1900 is a typical year of the 1900 Gregorian calendar \n",
      "prediction: 1900 is a typical year of the 1900 Gregorian calendar\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "for i in data[-10:]:\n",
    "    text = \"আমি আবার বিয়ে করেছি।\"\n",
    "    pre = translate(model, i[0], bn_vocab, en_vocab, bn_tokenizer)\n",
    "    print(f\"input : {i[0]}\")\n",
    "    print(f\"Ground Truth : {i[1]}\")\n",
    "    print(f\"prediction: {pre}\")\n",
    "    print(\"================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be40937",
   "metadata": {},
   "source": [
    "## Reference\n",
    "1. https://torchtutorialstaging.z5.web.core.windows.net/beginner/translation_transformer.html\n",
    "2. https://arusl.medium.com/japanese-english-language-translation-with-transformer-using-pytorch-243738146806\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed68c264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
